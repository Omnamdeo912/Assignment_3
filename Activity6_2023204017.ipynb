{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpu4IRDG4NZJrtC7TeTy2s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omnamdeo912/Assignment_3/blob/main/Activity6_2023204017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibAJgZIBNFkO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchtext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetForCBOW(torch.utils.data.Dataset):\n",
        "  def __init__(self, text, context_length=5):  # 1) Chnaged context_size to 5\n",
        "    text_list = text.split(\".\")\n",
        "    text_list_token = [t.split(\" \") for t in text_list]\n",
        "    n_grams = []\n",
        "    self.vocab = torchtext.vocab.build_vocab_from_iterator(text_list_token)\n",
        "\n",
        "    for sent in text_list_token:\n",
        "      len_sent = len(sent)\n",
        "      if len_sent >= 5:\n",
        "        for i in range(len_sent-4):\n",
        "          n_gram = sent[i: i+5]\n",
        "          n_grams.append(n_gram)\n",
        "    self.n_grams_indices = [self.vocab.lookup_indices(n_gram) for n_gram in n_grams]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.n_grams_indices)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = (self.n_grams_indices[index][0], self.n_grams_indices[index][-1])\n",
        "    y = self.n_grams_indices[index][1]\n",
        "    return torch.tensor(x), torch.tensor(y)"
      ],
      "metadata": {
        "id": "_EL9aPPATFcE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Here i am taking bieeger corpus of words :\n",
        "```\n",
        "\" Technology has changed the way we live in big ways. It affects our society in many different aspects. Let's look at some ways technology has made an impact.\n",
        "\n",
        "Communication is way faster now. We can talk to anyone, anywhere in an instant. Social media and texting help us stay connected. But sometimes, we forget to talk face-to-face.\n",
        "\n",
        "Learning is easier with technology. We can study online and use apps to help us understand better. But not everyone has access to these tools, which isn't fair.\n",
        "\n",
        "Shopping has shifted online too. We can buy things from home. It's convenient, but traditional stores struggle.\n",
        "\n",
        "Jobs have changed with technology. Some jobs disappeared, but new ones popped up. Working from home is more common now.\n",
        "\n",
        "Healthcare got better with technology. Doctors use machines to find problems early. But we worry about keeping our health data safe.\n",
        "\n",
        "Entertainment is everywhere with technology. We watch shows, play games, and even explore different worlds in virtual reality. But too much screen time isn't good for us.\n",
        "\n",
        "Technology helps the environment too. Solar panels and smart devices save energy. But making tech gadgets can harm the Earth.\n",
        "\n",
        "In the end, technology is a mixed bag. It brings good things like fast communication, easy learning, and better healthcare. But it also brings challenges like privacy worries and environmental concerns. We need to use technology wisely to make sure it helps our society without causing harm.\"\n",
        "```"
      ],
      "metadata": {
        "id": "Wo7lQvjXWk4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Taking bigger corpus text\n",
        "\n",
        "dataset = DatasetForCBOW(\"Technology has changed the way we live in big ways. It affects our society in many different aspects. Let's look at some ways technology has made an impact.Communication is way faster now. We can talk to anyone, anywhere in an instant. Social media and texting help us stay connected. But sometimes, we forget to talk face-to-face.Learning is easier with technology. We can study online and use apps to help us understand better. But not everyone has access to these tools, which isn't fair.Shopping has shifted online too. We can buy things from home. It's convenient, but traditional stores struggle.Jobs have changed with technology. Some jobs disappeared, but new ones popped up. Working from home is more common now.Healthcare got better with technology. Doctors use machines to find problems early. But we worry about keeping our health data safe.Entertainment is everywhere with technology. We watch shows, play games, and even explore different worlds in virtual reality. But too much screen time isn't good for us.Technology helps the environment too. Solar panels and smart devices save energy. But making tech gadgets can harm the Earth.In the end, technology is a mixed bag. It brings good things like fast communication, easy learning, and better healthcare. But it also brings challenges like privacy worries and environmental concerns. We need to use technology wisely to make sure it helps our society without causing harm.\")\n",
        "\n",
        "print(\"dataset size:\", len(dataset))\n",
        "print(dataset[4])\n",
        "\n",
        "for i in range(len(dataset)):  # Printing the list of tensors after n-gram processing\n",
        "    sample = dataset[i]\n",
        "    print(\"Sample {}: {}\".format(i, sample))\n",
        "\n",
        "print(dataset.vocab.get_itos())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-aPBRBlTaEF",
        "outputId": "7a83527f-5d7d-4aa5-c462-aaab7a2a4c95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 141\n",
            "(tensor([39, 67]), tensor(17))\n",
            "Sample 0: (tensor([19, 39]), tensor(8))\n",
            "Sample 1: (tensor([ 8, 17]), tensor(23))\n",
            "Sample 2: (tensor([ 23, 108]), tensor(10))\n",
            "Sample 3: (tensor([10,  9]), tensor(39))\n",
            "Sample 4: (tensor([39, 67]), tensor(17))\n",
            "Sample 5: (tensor([17, 40]), tensor(108))\n",
            "Sample 6: (tensor([ 0, 36]), tensor(18))\n",
            "Sample 7: (tensor([18,  9]), tensor(59))\n",
            "Sample 8: (tensor([ 59, 114]), tensor(13))\n",
            "Sample 9: (tensor([13, 24]), tensor(36))\n",
            "Sample 10: (tensor([36, 64]), tensor(9))\n",
            "Sample 11: (tensor([  0, 135]), tensor(50))\n",
            "Sample 12: (tensor([50, 40]), tensor(109))\n",
            "Sample 13: (tensor([109,   1]), tensor(65))\n",
            "Sample 14: (tensor([65,  8]), tensor(135))\n",
            "Sample 15: (tensor([135, 111]), tensor(40))\n",
            "Sample 16: (tensor([40, 20]), tensor(1))\n",
            "Sample 17: (tensor([  1, 103]), tensor(8))\n",
            "Sample 18: (tensor([41, 34]), tensor(6))\n",
            "Sample 19: (tensor([0, 2]), tensor(5))\n",
            "Sample 20: (tensor([ 5, 61]), tensor(7))\n",
            "Sample 21: (tensor([ 7, 62]), tensor(37))\n",
            "Sample 22: (tensor([37,  9]), tensor(2))\n",
            "Sample 23: (tensor([ 2, 20]), tensor(61))\n",
            "Sample 24: (tensor([ 61, 104]), tensor(62))\n",
            "Sample 25: (tensor([  0, 143]), tensor(52))\n",
            "Sample 26: (tensor([52, 28]), tensor(115))\n",
            "Sample 27: (tensor([115,  15]), tensor(4))\n",
            "Sample 28: (tensor([  4, 137]), tensor(143))\n",
            "Sample 29: (tensor([143,  74]), tensor(28))\n",
            "Sample 30: (tensor([ 0, 96]), tensor(3))\n",
            "Sample 31: (tensor([3, 2]), tensor(136))\n",
            "Sample 32: (tensor([136,  37]), tensor(17))\n",
            "Sample 33: (tensor([17, 90]), tensor(96))\n",
            "Sample 34: (tensor([49,  1]), tensor(6))\n",
            "Sample 35: (tensor([ 0, 35]), tensor(5))\n",
            "Sample 36: (tensor([5, 4]), tensor(7))\n",
            "Sample 37: (tensor([ 7, 16]), tensor(140))\n",
            "Sample 38: (tensor([140,  63]), tensor(35))\n",
            "Sample 39: (tensor([35,  2]), tensor(4))\n",
            "Sample 40: (tensor([ 4, 28]), tensor(16))\n",
            "Sample 41: (tensor([16, 15]), tensor(63))\n",
            "Sample 42: (tensor([ 63, 148]), tensor(2))\n",
            "Sample 43: (tensor([ 2, 12]), tensor(28))\n",
            "Sample 44: (tensor([0, 8]), tensor(3))\n",
            "Sample 45: (tensor([ 3, 58]), tensor(121))\n",
            "Sample 46: (tensor([121,   2]), tensor(87))\n",
            "Sample 47: (tensor([ 87, 144]), tensor(8))\n",
            "Sample 48: (tensor([  8, 146]), tensor(58))\n",
            "Sample 49: (tensor([ 58, 152]), tensor(2))\n",
            "Sample 50: (tensor([ 2, 31]), tensor(144))\n",
            "Sample 51: (tensor([144,  91]), tensor(146))\n",
            "Sample 52: (tensor([51, 14]), tensor(8))\n",
            "Sample 53: (tensor([ 0, 38]), tensor(5))\n",
            "Sample 54: (tensor([ 5, 25]), tensor(7))\n",
            "Sample 55: (tensor([ 7, 30]), tensor(68))\n",
            "Sample 56: (tensor([  0, 147]), tensor(47))\n",
            "Sample 57: (tensor([ 47, 138]), tensor(75))\n",
            "Sample 58: (tensor([ 75, 139]), tensor(22))\n",
            "Sample 59: (tensor([48,  1]), tensor(100))\n",
            "Sample 60: (tensor([ 0, 22]), tensor(54))\n",
            "Sample 61: (tensor([ 54, 120]), tensor(105))\n",
            "Sample 62: (tensor([105, 122]), tensor(78))\n",
            "Sample 63: (tensor([ 78, 125]), tensor(22))\n",
            "Sample 64: (tensor([ 22, 149]), tensor(120))\n",
            "Sample 65: (tensor([0, 6]), tensor(55))\n",
            "Sample 66: (tensor([ 55, 117]), tensor(25))\n",
            "Sample 67: (tensor([25, 71]), tensor(30))\n",
            "Sample 68: (tensor([30, 34]), tensor(6))\n",
            "Sample 69: (tensor([45,  1]), tensor(99))\n",
            "Sample 70: (tensor([0, 2]), tensor(42))\n",
            "Sample 71: (tensor([42, 94]), tensor(16))\n",
            "Sample 72: (tensor([ 16, 127]), tensor(110))\n",
            "Sample 73: (tensor([110,  79]), tensor(2))\n",
            "Sample 74: (tensor([ 0, 57]), tensor(3))\n",
            "Sample 75: (tensor([  3, 106]), tensor(17))\n",
            "Sample 76: (tensor([17, 13]), tensor(157))\n",
            "Sample 77: (tensor([157, 101]), tensor(57))\n",
            "Sample 78: (tensor([57, 76]), tensor(106))\n",
            "Sample 79: (tensor([106, 129]), tensor(13))\n",
            "Sample 80: (tensor([44,  1]), tensor(6))\n",
            "Sample 81: (tensor([  0, 124]), tensor(5))\n",
            "Sample 82: (tensor([ 5, 98]), tensor(151))\n",
            "Sample 83: (tensor([151,   4]), tensor(133))\n",
            "Sample 84: (tensor([133,  86]), tensor(124))\n",
            "Sample 85: (tensor([124,  89]), tensor(98))\n",
            "Sample 86: (tensor([98, 24]), tensor(4))\n",
            "Sample 87: (tensor([  4, 155]), tensor(86))\n",
            "Sample 88: (tensor([86,  9]), tensor(89))\n",
            "Sample 89: (tensor([ 89, 150]), tensor(24))\n",
            "Sample 90: (tensor([ 24, 128]), tensor(155))\n",
            "Sample 91: (tensor([  0, 131]), tensor(3))\n",
            "Sample 92: (tensor([  3, 145]), tensor(14))\n",
            "Sample 93: (tensor([14, 31]), tensor(118))\n",
            "Sample 94: (tensor([118,  26]), tensor(131))\n",
            "Sample 95: (tensor([131,  95]), tensor(145))\n",
            "Sample 96: (tensor([145,  15]), tensor(31))\n",
            "Sample 97: (tensor([19, 14]), tensor(29))\n",
            "Sample 98: (tensor([  0, 134]), tensor(53))\n",
            "Sample 99: (tensor([53, 77]), tensor(123))\n",
            "Sample 100: (tensor([123, 130]), tensor(4))\n",
            "Sample 101: (tensor([ 4, 83]), tensor(134))\n",
            "Sample 102: (tensor([ 0, 97]), tensor(3))\n",
            "Sample 103: (tensor([3, 7]), tensor(113))\n",
            "Sample 104: (tensor([113,  27]), tensor(142))\n",
            "Sample 105: (tensor([142,  10]), tensor(97))\n",
            "Sample 106: (tensor([97, 43]), tensor(7))\n",
            "Sample 107: (tensor([46,  6]), tensor(10))\n",
            "Sample 108: (tensor([10, 56]), tensor(82))\n",
            "Sample 109: (tensor([ 82, 116]), tensor(1))\n",
            "Sample 110: (tensor([ 1, 66]), tensor(6))\n",
            "Sample 111: (tensor([ 0, 38]), tensor(18))\n",
            "Sample 112: (tensor([18, 33]), tensor(21))\n",
            "Sample 113: (tensor([21, 92]), tensor(26))\n",
            "Sample 114: (tensor([26, 72]), tensor(38))\n",
            "Sample 115: (tensor([38, 81]), tensor(33))\n",
            "Sample 116: (tensor([ 33, 107]), tensor(92))\n",
            "Sample 117: (tensor([92,  4]), tensor(72))\n",
            "Sample 118: (tensor([72, 12]), tensor(81))\n",
            "Sample 119: (tensor([ 81, 102]), tensor(107))\n",
            "Sample 120: (tensor([ 0, 21]), tensor(3))\n",
            "Sample 121: (tensor([ 3, 70]), tensor(32))\n",
            "Sample 122: (tensor([32, 33]), tensor(60))\n",
            "Sample 123: (tensor([ 60, 126]), tensor(21))\n",
            "Sample 124: (tensor([ 21, 156]), tensor(70))\n",
            "Sample 125: (tensor([70,  4]), tensor(33))\n",
            "Sample 126: (tensor([33, 85]), tensor(126))\n",
            "Sample 127: (tensor([126,  73]), tensor(156))\n",
            "Sample 128: (tensor([ 0, 16]), tensor(5))\n",
            "Sample 129: (tensor([5, 1]), tensor(119))\n",
            "Sample 130: (tensor([119, 153]), tensor(2))\n",
            "Sample 131: (tensor([2, 2]), tensor(16))\n",
            "Sample 132: (tensor([ 16, 112]), tensor(1))\n",
            "Sample 133: (tensor([  1, 141]), tensor(153))\n",
            "Sample 134: (tensor([153,  32]), tensor(2))\n",
            "Sample 135: (tensor([ 2, 29]), tensor(112))\n",
            "Sample 136: (tensor([112,  13]), tensor(141))\n",
            "Sample 137: (tensor([141,  36]), tensor(32))\n",
            "Sample 138: (tensor([ 32, 154]), tensor(29))\n",
            "Sample 139: (tensor([29, 69]), tensor(13))\n",
            "Sample 140: (tensor([13, 27]), tensor(36))\n",
            "['', 'technology', 'to', 'But', 'and', 'We', 'is', 'can', 'has', 'in', 'the', 'with', 'better', 'our', 'too', 'us', 'use', 'we', 'It', 'Technology', 'an', 'brings', 'but', 'changed', 'different', 'from', 'good', 'harm', 'help', 'helps', 'home', \"isn't\", 'it', 'like', 'now', 'online', 'society', 'talk', 'things', 'way', 'ways', 'Communication', 'Doctors', 'Earth', 'Entertainment', 'Healthcare', 'In', \"It's\", 'Jobs', 'Learning', \"Let's\", 'Shopping', 'Social', 'Solar', 'Some', 'Working', 'a', 'about', 'access', 'affects', 'also', 'anyone,', 'anywhere', 'apps', 'aspects', 'at', 'bag', 'big', 'buy', 'causing', 'challenges', 'common', 'communication,', 'concerns', 'connected', 'convenient,', 'data', 'devices', 'disappeared,', 'early', 'easier', 'easy', 'end,', 'energy', 'environment', 'environmental', 'even', 'everyone', 'everywhere', 'explore', 'face-to-face', 'fair', 'fast', 'faster', 'find', 'for', 'forget', 'gadgets', 'games,', 'got', 'have', 'health', 'healthcare', 'impact', 'instant', 'jobs', 'keeping', 'learning,', 'live', 'look', 'machines', 'made', 'make', 'making', 'many', 'media', 'mixed', 'more', 'much', 'need', 'new', 'not', 'ones', 'panels', 'play', 'popped', 'privacy', 'problems', 'reality', 'safe', 'save', 'screen', 'shifted', 'shows,', 'smart', 'some', 'sometimes,', 'stay', 'stores', 'struggle', 'study', 'sure', 'tech', 'texting', 'these', 'time', 'tools,', 'traditional', 'understand', 'up', 'virtual', 'watch', 'which', 'wisely', 'without', 'worlds', 'worries', 'worry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=3)"
      ],
      "metadata": {
        "id": "zBktRDY2V-nc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOWModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab, embedding_dim, context_size):\n",
        "        super(CBOWModeler, self).__init__()\n",
        "        vocab_size = len(vocab)\n",
        "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = torch.nn.Linear(embedding_dim, vocab_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "        self.loss_fun = torch.nn.CrossEntropyLoss()\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs: b, s\n",
        "        embeds = self.embeddings(inputs) # b, s, dim\n",
        "        context_embed = embeds.sum(dim=1) # b, s\n",
        "        out1 = self.relu(context_embed) # b, s\n",
        "        out2 = self.linear(out1) # b, v\n",
        "        log_probs = self.softmax(out2)\n",
        "        return out2, log_probs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jwsbaFkPQCNu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOWModeler(dataset.vocab, 100, 5).to(\"cuda\")\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(100):\n",
        "  for batch in dataloader:\n",
        "    x, y = batch\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "    optim.zero_grad()\n",
        "    out, preds = model(x)\n",
        "    loss = model.loss_fun(out, y)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "  print(loss)\n",
        "    # print(out.shape, preds.shape)\n",
        "  # print(out, preds)"
      ],
      "metadata": {
        "id": "E8HWKtzYWcC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "7d7842ed-60d7-4492-bfc0-99e04102c719"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c8ea0f31be74>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCBOWModeler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.embeddings.weight\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jUlfuzdjaKm",
        "outputId": "11f2ad54-d365-4da2-ed9a-b73fc6beaa0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([158, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}